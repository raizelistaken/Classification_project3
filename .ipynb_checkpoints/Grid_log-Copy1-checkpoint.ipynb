{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('mushroom_ft_engineer.csv', index_col = 0)\n",
    "df2 = pd.read_csv('le_mushroom_ft_engineer.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df2['class']\n",
    "X = df2.drop(['class', 'spore-print-color', 'veil-type'] , axis = 1)\n",
    "\n",
    "# Split X and y with even class distributions\n",
    "# stratify to create randomness in your data but one that also has the same propoertoins across train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scale the data\n",
    "ss = StandardScaler()\n",
    "ss.fit(X_train)\n",
    "X_train = pd.DataFrame(ss.transform(X_train), columns=X_train.columns)\n",
    "X_test = pd.DataFrame(ss.transform(X_test), columns=X_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
      "                   random_state=42, solver='warn', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\akams\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9987692307692307"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log = LogisticRegression(random_state=42)\n",
    "print(log.fit(X_train, y_train))\n",
    "log.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cap-shape</th>\n",
       "      <th>cap-surface</th>\n",
       "      <th>cap-color</th>\n",
       "      <th>bruises</th>\n",
       "      <th>odor</th>\n",
       "      <th>gill-attachment</th>\n",
       "      <th>gill-spacing</th>\n",
       "      <th>gill-size</th>\n",
       "      <th>gill-color</th>\n",
       "      <th>stalk-shape</th>\n",
       "      <th>...</th>\n",
       "      <th>ring-type</th>\n",
       "      <th>population</th>\n",
       "      <th>habitat</th>\n",
       "      <th>human_interference</th>\n",
       "      <th>offensive_odor</th>\n",
       "      <th>c_molybdites</th>\n",
       "      <th>non_toxic_spore_color</th>\n",
       "      <th>prob_tox</th>\n",
       "      <th>prob_ed</th>\n",
       "      <th>no_rings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.567684</td>\n",
       "      <td>0.221589</td>\n",
       "      <td>1.359774</td>\n",
       "      <td>0.844107</td>\n",
       "      <td>-0.394699</td>\n",
       "      <td>0.159888</td>\n",
       "      <td>-0.437225</td>\n",
       "      <td>-0.662169</td>\n",
       "      <td>-0.229030</td>\n",
       "      <td>-1.141838</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.164559</td>\n",
       "      <td>1.081015</td>\n",
       "      <td>-1.271931</td>\n",
       "      <td>-0.511802</td>\n",
       "      <td>-1.068010</td>\n",
       "      <td>-0.09734</td>\n",
       "      <td>-0.151064</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.29798</td>\n",
       "      <td>-0.06459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.543240</td>\n",
       "      <td>1.066229</td>\n",
       "      <td>0.196567</td>\n",
       "      <td>-1.184684</td>\n",
       "      <td>0.617793</td>\n",
       "      <td>0.159888</td>\n",
       "      <td>-0.437225</td>\n",
       "      <td>-0.662169</td>\n",
       "      <td>1.270230</td>\n",
       "      <td>-1.141838</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.276853</td>\n",
       "      <td>-2.117126</td>\n",
       "      <td>0.699610</td>\n",
       "      <td>1.953879</td>\n",
       "      <td>0.936321</td>\n",
       "      <td>-0.09734</td>\n",
       "      <td>-0.151064</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.29798</td>\n",
       "      <td>-0.06459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-2.765088</td>\n",
       "      <td>1.066229</td>\n",
       "      <td>-0.385036</td>\n",
       "      <td>0.844107</td>\n",
       "      <td>0.617793</td>\n",
       "      <td>0.159888</td>\n",
       "      <td>2.287152</td>\n",
       "      <td>-0.662169</td>\n",
       "      <td>1.570082</td>\n",
       "      <td>-1.141838</td>\n",
       "      <td>...</td>\n",
       "      <td>0.947735</td>\n",
       "      <td>-0.518055</td>\n",
       "      <td>-1.271931</td>\n",
       "      <td>-0.511802</td>\n",
       "      <td>0.936321</td>\n",
       "      <td>-0.09734</td>\n",
       "      <td>-0.151064</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.29798</td>\n",
       "      <td>-0.06459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.567684</td>\n",
       "      <td>1.066229</td>\n",
       "      <td>-1.257441</td>\n",
       "      <td>0.844107</td>\n",
       "      <td>1.630286</td>\n",
       "      <td>0.159888</td>\n",
       "      <td>-0.437225</td>\n",
       "      <td>1.510188</td>\n",
       "      <td>-0.828734</td>\n",
       "      <td>0.875781</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.276853</td>\n",
       "      <td>0.281480</td>\n",
       "      <td>1.093919</td>\n",
       "      <td>-0.511802</td>\n",
       "      <td>-1.068010</td>\n",
       "      <td>-0.09734</td>\n",
       "      <td>-0.151064</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.29798</td>\n",
       "      <td>-0.06459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.678608</td>\n",
       "      <td>0.221589</td>\n",
       "      <td>-1.257441</td>\n",
       "      <td>0.844107</td>\n",
       "      <td>-0.394699</td>\n",
       "      <td>0.159888</td>\n",
       "      <td>-0.437225</td>\n",
       "      <td>1.510188</td>\n",
       "      <td>-0.828734</td>\n",
       "      <td>0.875781</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.276853</td>\n",
       "      <td>0.281480</td>\n",
       "      <td>-0.089006</td>\n",
       "      <td>1.953879</td>\n",
       "      <td>-1.068010</td>\n",
       "      <td>-0.09734</td>\n",
       "      <td>-0.151064</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.29798</td>\n",
       "      <td>-0.06459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6494</th>\n",
       "      <td>-0.543240</td>\n",
       "      <td>1.066229</td>\n",
       "      <td>-1.257441</td>\n",
       "      <td>0.844107</td>\n",
       "      <td>1.630286</td>\n",
       "      <td>0.159888</td>\n",
       "      <td>-0.437225</td>\n",
       "      <td>1.510188</td>\n",
       "      <td>-0.828734</td>\n",
       "      <td>0.875781</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.276853</td>\n",
       "      <td>0.281480</td>\n",
       "      <td>1.093919</td>\n",
       "      <td>-0.511802</td>\n",
       "      <td>-1.068010</td>\n",
       "      <td>-0.09734</td>\n",
       "      <td>-0.151064</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.29798</td>\n",
       "      <td>-0.06459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6495</th>\n",
       "      <td>-0.543240</td>\n",
       "      <td>0.221589</td>\n",
       "      <td>-1.257441</td>\n",
       "      <td>0.844107</td>\n",
       "      <td>0.617793</td>\n",
       "      <td>0.159888</td>\n",
       "      <td>2.287152</td>\n",
       "      <td>1.510188</td>\n",
       "      <td>1.570082</td>\n",
       "      <td>-1.141838</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.276853</td>\n",
       "      <td>0.281480</td>\n",
       "      <td>-0.877623</td>\n",
       "      <td>-0.511802</td>\n",
       "      <td>0.936321</td>\n",
       "      <td>-0.09734</td>\n",
       "      <td>-0.151064</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.29798</td>\n",
       "      <td>-0.06459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6496</th>\n",
       "      <td>0.567684</td>\n",
       "      <td>-1.467689</td>\n",
       "      <td>1.068973</td>\n",
       "      <td>0.844107</td>\n",
       "      <td>0.617793</td>\n",
       "      <td>0.159888</td>\n",
       "      <td>2.287152</td>\n",
       "      <td>-0.662169</td>\n",
       "      <td>0.670526</td>\n",
       "      <td>0.875781</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.276853</td>\n",
       "      <td>-2.916661</td>\n",
       "      <td>-1.271931</td>\n",
       "      <td>-0.511802</td>\n",
       "      <td>0.936321</td>\n",
       "      <td>-0.09734</td>\n",
       "      <td>-0.151064</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.29798</td>\n",
       "      <td>-0.06459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6497</th>\n",
       "      <td>-0.543240</td>\n",
       "      <td>-1.467689</td>\n",
       "      <td>-0.385036</td>\n",
       "      <td>-1.184684</td>\n",
       "      <td>0.617793</td>\n",
       "      <td>0.159888</td>\n",
       "      <td>-0.437225</td>\n",
       "      <td>-0.662169</td>\n",
       "      <td>1.570082</td>\n",
       "      <td>0.875781</td>\n",
       "      <td>...</td>\n",
       "      <td>0.947735</td>\n",
       "      <td>1.081015</td>\n",
       "      <td>1.093919</td>\n",
       "      <td>-0.511802</td>\n",
       "      <td>0.936321</td>\n",
       "      <td>-0.09734</td>\n",
       "      <td>-0.151064</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.29798</td>\n",
       "      <td>-0.06459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6498</th>\n",
       "      <td>0.567684</td>\n",
       "      <td>-1.467689</td>\n",
       "      <td>-1.257441</td>\n",
       "      <td>-1.184684</td>\n",
       "      <td>0.617793</td>\n",
       "      <td>0.159888</td>\n",
       "      <td>-0.437225</td>\n",
       "      <td>-0.662169</td>\n",
       "      <td>0.670526</td>\n",
       "      <td>0.875781</td>\n",
       "      <td>...</td>\n",
       "      <td>0.947735</td>\n",
       "      <td>0.281480</td>\n",
       "      <td>1.093919</td>\n",
       "      <td>-0.511802</td>\n",
       "      <td>0.936321</td>\n",
       "      <td>-0.09734</td>\n",
       "      <td>-0.151064</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.29798</td>\n",
       "      <td>-0.06459</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6499 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      cap-shape  cap-surface  cap-color   bruises      odor  gill-attachment  \\\n",
       "0      0.567684     0.221589   1.359774  0.844107 -0.394699         0.159888   \n",
       "1     -0.543240     1.066229   0.196567 -1.184684  0.617793         0.159888   \n",
       "2     -2.765088     1.066229  -0.385036  0.844107  0.617793         0.159888   \n",
       "3      0.567684     1.066229  -1.257441  0.844107  1.630286         0.159888   \n",
       "4      1.678608     0.221589  -1.257441  0.844107 -0.394699         0.159888   \n",
       "...         ...          ...        ...       ...       ...              ...   \n",
       "6494  -0.543240     1.066229  -1.257441  0.844107  1.630286         0.159888   \n",
       "6495  -0.543240     0.221589  -1.257441  0.844107  0.617793         0.159888   \n",
       "6496   0.567684    -1.467689   1.068973  0.844107  0.617793         0.159888   \n",
       "6497  -0.543240    -1.467689  -0.385036 -1.184684  0.617793         0.159888   \n",
       "6498   0.567684    -1.467689  -1.257441 -1.184684  0.617793         0.159888   \n",
       "\n",
       "      gill-spacing  gill-size  gill-color  stalk-shape  ...  ring-type  \\\n",
       "0        -0.437225  -0.662169   -0.229030    -1.141838  ...  -0.164559   \n",
       "1        -0.437225  -0.662169    1.270230    -1.141838  ...  -1.276853   \n",
       "2         2.287152  -0.662169    1.570082    -1.141838  ...   0.947735   \n",
       "3        -0.437225   1.510188   -0.828734     0.875781  ...  -1.276853   \n",
       "4        -0.437225   1.510188   -0.828734     0.875781  ...  -1.276853   \n",
       "...            ...        ...         ...          ...  ...        ...   \n",
       "6494     -0.437225   1.510188   -0.828734     0.875781  ...  -1.276853   \n",
       "6495      2.287152   1.510188    1.570082    -1.141838  ...  -1.276853   \n",
       "6496      2.287152  -0.662169    0.670526     0.875781  ...  -1.276853   \n",
       "6497     -0.437225  -0.662169    1.570082     0.875781  ...   0.947735   \n",
       "6498     -0.437225  -0.662169    0.670526     0.875781  ...   0.947735   \n",
       "\n",
       "      population   habitat  human_interference  offensive_odor  c_molybdites  \\\n",
       "0       1.081015 -1.271931           -0.511802       -1.068010      -0.09734   \n",
       "1      -2.117126  0.699610            1.953879        0.936321      -0.09734   \n",
       "2      -0.518055 -1.271931           -0.511802        0.936321      -0.09734   \n",
       "3       0.281480  1.093919           -0.511802       -1.068010      -0.09734   \n",
       "4       0.281480 -0.089006            1.953879       -1.068010      -0.09734   \n",
       "...          ...       ...                 ...             ...           ...   \n",
       "6494    0.281480  1.093919           -0.511802       -1.068010      -0.09734   \n",
       "6495    0.281480 -0.877623           -0.511802        0.936321      -0.09734   \n",
       "6496   -2.916661 -1.271931           -0.511802        0.936321      -0.09734   \n",
       "6497    1.081015  1.093919           -0.511802        0.936321      -0.09734   \n",
       "6498    0.281480  1.093919           -0.511802        0.936321      -0.09734   \n",
       "\n",
       "      non_toxic_spore_color  prob_tox  prob_ed  no_rings  \n",
       "0                 -0.151064       0.0  0.29798  -0.06459  \n",
       "1                 -0.151064       0.0  0.29798  -0.06459  \n",
       "2                 -0.151064       0.0  0.29798  -0.06459  \n",
       "3                 -0.151064       0.0  0.29798  -0.06459  \n",
       "4                 -0.151064       0.0  0.29798  -0.06459  \n",
       "...                     ...       ...      ...       ...  \n",
       "6494              -0.151064       0.0  0.29798  -0.06459  \n",
       "6495              -0.151064       0.0  0.29798  -0.06459  \n",
       "6496              -0.151064       0.0  0.29798  -0.06459  \n",
       "6497              -0.151064       0.0  0.29798  -0.06459  \n",
       "6498              -0.151064       0.0  0.29798  -0.06459  \n",
       "\n",
       "[6499 rows x 27 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\akams\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\akams\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\akams\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\akams\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\akams\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9989234314977065"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now with cross validation search\n",
    "val = cross_val_score(LogisticRegression(random_state=42),X_train,y_train,cv=5)\n",
    "val.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"C:\\Users\\akams\\anaconda3\\envs\\learn-env\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 431, in _process_worker\n    r = call_item()\n  File \"C:\\Users\\akams\\anaconda3\\envs\\learn-env\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 285, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"C:\\Users\\akams\\anaconda3\\envs\\learn-env\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 595, in __call__\n    return self.func(*args, **kwargs)\n  File \"C:\\Users\\akams\\anaconda3\\envs\\learn-env\\lib\\site-packages\\joblib\\parallel.py\", line 253, in __call__\n    for func, args, kwargs in self.items]\n  File \"C:\\Users\\akams\\anaconda3\\envs\\learn-env\\lib\\site-packages\\joblib\\parallel.py\", line 253, in <listcomp>\n    for func, args, kwargs in self.items]\n  File \"C:\\Users\\akams\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 516, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\akams\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\logistic.py\", line 1493, in fit\n    solver = _check_solver(self.solver, self.penalty, self.dual)\n  File \"C:\\Users\\akams\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\logistic.py\", line 446, in _check_solver\n    \"got %s penalty.\" % (solver, penalty))\nValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-2e107aaf3004>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mgridsearch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlog_grid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlog_param_grid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mgridsearch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    686\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    687\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 688\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    689\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    690\u001b[0m         \u001b[1;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1147\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1148\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1149\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1150\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1151\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params)\u001b[0m\n\u001b[0;32m    665\u001b[0m                                \u001b[1;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    666\u001b[0m                                in product(candidate_params,\n\u001b[1;32m--> 667\u001b[1;33m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[0;32m    668\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    669\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1042\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1043\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1044\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    919\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    920\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 921\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    922\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    923\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[0;32m    541\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 542\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    543\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    430\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 432\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    433\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    382\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    383\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 384\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    385\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    386\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty."
     ]
    }
   ],
   "source": [
    "log_param_grid = {\n",
    "    \"max_iter\": [10, 50, 100],\n",
    "    \"penalty\": ['l1', 'l2'],\n",
    "    \"class_weight\": ['balanced'],\n",
    "    \"solver\": ['lbfgs', 'saga']\n",
    "}\n",
    "\n",
    "\n",
    "log_grid = LogisticRegression()\n",
    "gridsearch = GridSearchCV(log_grid, log_param_grid, cv=3, return_train_score=True, n_jobs=-1, verbose=-1)\n",
    "\n",
    "gridsearch.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy: 99.92%\n",
      "\n",
      "Optimal Parameters: {'class_weight': 'balanced', 'max_iter': 10, 'penalty': 'l1'}\n",
      "Best Model: LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=10, multi_class='warn', n_jobs=None, penalty='l1',\n",
      "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing Accuracy: {:.4}%\".format(gridsearch.best_score_ * 100))\n",
    "print(\"\")\n",
    "print(\"Optimal Parameters: {}\".format(gridsearch.best_params_))\n",
    "\n",
    "# Actual model object fit with those best parameters\n",
    "# Shows default parameters that we did not specify\n",
    "print(\"Best Model: {}\".format(gridsearch.best_estimator_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9993846153846154"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridsearch.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
